#!/bin/bash

# Configuration
IMAGE_NAME="ntp-train"
DOCKERFILE_PATH=".devcontainer/Dockerfile"
STORAGE_PATH="/home/$(whoami)/ai_storage"

# --- NEW: Check for API Key ---
# If a command line argument is provided, use it. Otherwise, use the env var.
WANDB_KEY=${1:-$WANDB_API_KEY}

if [ -z "$WANDB_KEY" ]; then
    echo "‚ö†Ô∏è Warning: No WANDB_API_KEY provided. Training might fail or run offline."
fi

echo "üîç Step 1: Checking Docker Environment..."

# 1. Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "‚ùå Error: Docker is not running."
    exit 1
fi

# 2. Build the image (Removing the 'if exists' check)
# It is better to run 'build' every time. If nothing changed, 
# Docker's layer caching makes this take 0.5 seconds anyway.
echo "üèóÔ∏è  Ensuring image '$IMAGE_NAME' is up to date..."
docker build -t $IMAGE_NAME -f $DOCKERFILE_PATH .

echo "üß™ Step 2: Validating GPU & Integrity..."

# Check GPU connectivity inside the container
if docker run --rm --gpus all $IMAGE_NAME nvidia-smi > /dev/null 2>&1; then
    echo "‚úÖ GPU Passthrough OK."
else
    echo "‚ùå Error: Docker cannot see your 3090. Check nvidia-container-toolkit."
    exit 1
fi

echo "üöÄ Step 3: Launching Training..."

# 4. Execute with Environment Variables and Mounts
# We use -e to pass the key you have in your local terminal session
# docker run --rm --gpus all \
#     -e WANDB_API_KEY="$WANDB_KEY" \
#     -v "$(pwd):/" \
#     -v "$STORAGE_PATH:/storage" \
#     $IMAGE_NAME \
#     python main/train.py \
#     --data_dir /storage/datasets \
#     --output_dir /storage/checkpoints

docker run --rm --gpus all \
    -e WANDB_API_KEY="$WANDB_KEY" \
    -e WANDB_DIR="/storage/wandb" \
    -e MLFLOW_TRACKING_URI="file:///storage/mlruns" \
    -v "$(pwd):/app" \
    -v "/home/fypits25/Documents/ted_backyard/ai_storage" \
    ntp-train:latest \
    python main/train.py

# 5. Cleanup dangling images to save space on your 3090
docker image prune -f